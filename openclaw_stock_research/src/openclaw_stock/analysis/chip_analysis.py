"""
ç­¹ç åˆ†å¸ƒï¼ˆæˆæœ¬åˆ†å¸ƒï¼‰åˆ†ææ¨¡å—

åŸºäºä¸œæ–¹è´¢å¯Œç½‘ç­¹ç åˆ†å¸ƒæ•°æ®ï¼Œæä¾›ï¼š
- è·åˆ©æ¯”ä¾‹åˆ†æï¼ˆå½“å‰ä»·æ ¼ä¸‹ç›ˆåˆ©ç­¹ç å æ¯”ï¼‰
- å¹³å‡æˆæœ¬è®¡ç®—
- ç­¹ç é›†ä¸­åº¦åˆ†æï¼ˆ90%å’Œ70%æˆæœ¬åŒºé—´ï¼‰
- ç­¹ç è¶‹åŠ¿åˆ¤æ–­

æ•°æ®æ¥æº: akshare stock_cyq_em æ¥å£ï¼ˆä¸œæ–¹è´¢å¯Œç½‘-æ¦‚å¿µæ¿-è¡Œæƒ…ä¸­å¿ƒ-æ—¥K-ç­¹ç åˆ†å¸ƒï¼‰
"""

from typing import Literal, Optional, Dict, Any, List
from datetime import datetime
import pandas as pd
import numpy as np

from ..core.exceptions import DataSourceError, CalculationError
from ..utils.logger import get_logger

try:
    import akshare as ak
except ImportError:
    ak = None

logger = get_logger(__name__)


def fetch_chip_distribution(
    symbol: str,
    adjust: Literal["qfq", "hfq", ""] = "qfq"
) -> pd.DataFrame:
    """
    è·å–ç­¹ç åˆ†å¸ƒæ•°æ®

    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç ï¼ˆçº¯æ•°å­—ï¼Œå¦‚ '601127'ï¼‰
        adjust: å¤æƒæ–¹å¼ - "qfq"å‰å¤æƒ, "hfq"åå¤æƒ, ""ä¸å¤æƒ

    è¿”å›:
        DataFrameï¼ŒåŒ…å«åˆ—:
        - æ—¥æœŸ, è·åˆ©æ¯”ä¾‹, å¹³å‡æˆæœ¬
        - 90æˆæœ¬-ä½, 90æˆæœ¬-é«˜, 90é›†ä¸­åº¦
        - 70æˆæœ¬-ä½, 70æˆæœ¬-é«˜, 70é›†ä¸­åº¦

    å¼‚å¸¸:
        DataSourceError: æ•°æ®è·å–å¤±è´¥
    """
    if ak is None:
        raise DataSourceError("akshareåº“æœªå®‰è£…")

    try:
        df = ak.stock_cyq_em(symbol=symbol, adjust=adjust)
        if df is None or df.empty:
            raise DataSourceError(f"æœªè·å–åˆ° {symbol} çš„ç­¹ç åˆ†å¸ƒæ•°æ®")
        return df
    except DataSourceError:
        raise
    except Exception as e:
        raise DataSourceError(f"è·å– {symbol} ç­¹ç åˆ†å¸ƒæ•°æ®å¤±è´¥: {e}")


def analyze_chip_distribution(
    symbol: str,
    current_price: Optional[float] = None,
    adjust: Literal["qfq", "hfq", ""] = "qfq"
) -> Dict[str, Any]:
    """
    ç­¹ç åˆ†å¸ƒç»¼åˆåˆ†æ

    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç ï¼ˆçº¯æ•°å­—ï¼Œå¦‚ '601127'ï¼‰
        current_price: å½“å‰ä»·æ ¼ï¼ˆå¯é€‰ï¼Œç”¨äºè¾…åŠ©åˆ¤æ–­ï¼‰
        adjust: å¤æƒæ–¹å¼

    è¿”å›:
        {
            'latest': {æœ€æ–°ä¸€æ—¥ç­¹ç æ•°æ®},
            'trend': {ç­¹ç è¶‹åŠ¿åˆ†æ},
            'assessment': {ç»¼åˆè¯„ä¼°}
        }

    å¼‚å¸¸:
        DataSourceError: æ•°æ®è·å–å¤±è´¥
        CalculationError: è®¡ç®—å¤±è´¥
    """
    logger.info(f"[chip_analysis] å¼€å§‹åˆ†æ {symbol} çš„ç­¹ç åˆ†å¸ƒ")

    try:
        df = fetch_chip_distribution(symbol, adjust=adjust)
    except DataSourceError as e:
        logger.warning(f"[chip_analysis] è·å–ç­¹ç æ•°æ®å¤±è´¥: {e}")
        return _empty_chip_result(str(e))

    try:
        result = {}

        # --- 1. æœ€æ–°ä¸€æ—¥ç­¹ç æ•°æ® ---
        latest = df.iloc[-1]
        result["latest"] = {
            "date": str(latest["æ—¥æœŸ"]),
            "winner_rate": _safe_float(latest["è·åˆ©æ¯”ä¾‹"]),
            "average_cost": _safe_float(latest["å¹³å‡æˆæœ¬"]),
            "cost_90_low": _safe_float(latest["90æˆæœ¬-ä½"]),
            "cost_90_high": _safe_float(latest["90æˆæœ¬-é«˜"]),
            "concentration_90": _safe_float(latest["90é›†ä¸­åº¦"]),
            "cost_70_low": _safe_float(latest["70æˆæœ¬-ä½"]),
            "cost_70_high": _safe_float(latest["70æˆæœ¬-é«˜"]),
            "concentration_70": _safe_float(latest["70é›†ä¸­åº¦"]),
        }

        # è®¡ç®—90%å’Œ70%æˆæœ¬åŒºé—´å®½åº¦
        cost_90_range = result["latest"]["cost_90_high"] - result["latest"]["cost_90_low"]
        cost_70_range = result["latest"]["cost_70_high"] - result["latest"]["cost_70_low"]
        result["latest"]["cost_90_range"] = round(cost_90_range, 2)
        result["latest"]["cost_70_range"] = round(cost_70_range, 2)

        # --- 2. ç­¹ç è¶‹åŠ¿åˆ†æï¼ˆå¯¹æ¯”è¿‘æœŸå˜åŒ–ï¼‰ ---
        result["trend"] = _analyze_chip_trend(df)

        # --- 3. ç»¼åˆè¯„ä¼° ---
        result["assessment"] = _assess_chip_status(
            result["latest"], result["trend"], current_price
        )

        logger.info(f"[chip_analysis] {symbol} ç­¹ç åˆ†æå®Œæˆ")
        return result

    except Exception as e:
        logger.error(f"[chip_analysis] ç­¹ç åˆ†æè®¡ç®—å¤±è´¥: {e}")
        raise CalculationError(f"ç­¹ç åˆ†æè®¡ç®—å¤±è´¥: {e}")


def _safe_float(value) -> float:
    """å®‰å…¨è½¬æ¢ä¸ºfloatï¼Œå¤„ç†NaNç­‰æƒ…å†µ"""
    try:
        v = float(value)
        return round(v, 4) if not np.isnan(v) else 0.0
    except (ValueError, TypeError):
        return 0.0


def _analyze_chip_trend(df: pd.DataFrame) -> Dict[str, Any]:
    """
    åˆ†æç­¹ç å˜åŒ–è¶‹åŠ¿ï¼ˆå¢å¼ºç‰ˆï¼‰

    å¤šå‘¨æœŸå¯¹æ¯” + ä¸»åŠ›è¡Œä¸ºæ¨æ–­ï¼š
    - çŸ­æœŸ(5æ—¥)ã€ä¸­æœŸ(10æ—¥)ã€é•¿æœŸ(20æ—¥)ä¸‰ä¸ªç»´åº¦
    - ç­¹ç è¿ç§»é€Ÿåº¦åˆ†æ
    - é›†ä¸­åº¦å˜åŒ–ç‡ï¼ˆåæ˜ ä¸»åŠ›æ“ä½œåŠ›åº¦ï¼‰
    - è·åˆ©æ¯”ä¾‹ä¸é›†ä¸­åº¦äº¤å‰åˆ†æï¼ˆæ¨æ–­ä¸»åŠ›å¸ç­¹/æ´¾å‘ï¼‰
    - æˆæœ¬ä¸­å¿ƒç§»åŠ¨æ–¹å‘å’Œé€Ÿåº¦
    """
    trend = {
        "concentration_trend": "stable",  # concentrating / dispersing / stable
        "cost_center_trend": "stable",    # rising / falling / stable
        "winner_rate_trend": "stable",    # rising / falling / stable
        "period_days": 0,
        "institutional_signal": "neutral",  # accumulating / distributing / neutral / unclear
        "institutional_confidence": "low",  # low / medium / high
        "multi_period": {},                 # å¤šå‘¨æœŸåˆ†æ
        "details": {},
        "interpretation": []               # äººè¯è§£è¯»
    }

    if len(df) < 5:
        return trend

    trend["period_days"] = len(df)

    # ========== å¤šå‘¨æœŸåˆ†æ ==========
    periods = {"short": 5, "medium": 10, "long": 20}
    for period_name, period_len in periods.items():
        if len(df) < period_len + 5:
            continue

        recent = df.iloc[-period_len:]
        earlier = df.iloc[-(period_len * 2):-period_len] if len(df) >= period_len * 2 else df.iloc[:period_len]

        recent_conc_90 = recent["90é›†ä¸­åº¦"].mean()
        earlier_conc_90 = earlier["90é›†ä¸­åº¦"].mean()
        recent_conc_70 = recent["70é›†ä¸­åº¦"].mean()
        earlier_conc_70 = earlier["70é›†ä¸­åº¦"].mean()
        recent_avg_cost = recent["å¹³å‡æˆæœ¬"].mean()
        earlier_avg_cost = earlier["å¹³å‡æˆæœ¬"].mean()
        recent_winner = recent["è·åˆ©æ¯”ä¾‹"].mean()
        earlier_winner = earlier["è·åˆ©æ¯”ä¾‹"].mean()

        conc_90_change = (recent_conc_90 - earlier_conc_90) / earlier_conc_90 if earlier_conc_90 != 0 else 0
        conc_70_change = (recent_conc_70 - earlier_conc_70) / earlier_conc_70 if earlier_conc_70 != 0 else 0
        cost_change = (recent_avg_cost - earlier_avg_cost) / earlier_avg_cost if earlier_avg_cost != 0 else 0
        winner_change = recent_winner - earlier_winner

        trend["multi_period"][period_name] = {
            "days": period_len,
            "concentration_90_change_pct": round(conc_90_change * 100, 2),
            "concentration_70_change_pct": round(conc_70_change * 100, 2),
            "cost_center_change_pct": round(cost_change * 100, 2),
            "winner_rate_change": round(winner_change * 100, 2),
            "recent_avg_cost": round(float(recent_avg_cost), 2),
            "earlier_avg_cost": round(float(earlier_avg_cost), 2),
            "recent_concentration_90": round(float(recent_conc_90), 4),
            "recent_winner_rate": round(float(recent_winner * 100), 2),
        }

    # ========== ä¸»è¶‹åŠ¿åˆ¤æ–­ï¼ˆåŸºäºçŸ­æœŸæ•°æ®ï¼‰ ==========
    recent_n = min(5, len(df))
    early_start = max(0, len(df) - 20)
    early_end = max(recent_n, len(df) - 10)

    if early_end <= early_start:
        return trend

    recent = df.iloc[-recent_n:]
    early = df.iloc[early_start:early_end]

    recent_conc_90 = recent["90é›†ä¸­åº¦"].mean()
    early_conc_90 = early["90é›†ä¸­åº¦"].mean()

    if recent_conc_90 < early_conc_90 * 0.95:
        trend["concentration_trend"] = "concentrating"
    elif recent_conc_90 > early_conc_90 * 1.05:
        trend["concentration_trend"] = "dispersing"

    trend["details"]["recent_concentration_90"] = round(float(recent_conc_90), 4)
    trend["details"]["early_concentration_90"] = round(float(early_conc_90), 4)

    # æˆæœ¬ä¸­å¿ƒè¶‹åŠ¿
    recent_avg_cost = recent["å¹³å‡æˆæœ¬"].mean()
    early_avg_cost = early["å¹³å‡æˆæœ¬"].mean()

    if recent_avg_cost > early_avg_cost * 1.02:
        trend["cost_center_trend"] = "rising"
    elif recent_avg_cost < early_avg_cost * 0.98:
        trend["cost_center_trend"] = "falling"

    trend["details"]["recent_avg_cost"] = round(float(recent_avg_cost), 2)
    trend["details"]["early_avg_cost"] = round(float(early_avg_cost), 2)

    # è·åˆ©æ¯”ä¾‹è¶‹åŠ¿
    recent_winner = recent["è·åˆ©æ¯”ä¾‹"].mean()
    early_winner = early["è·åˆ©æ¯”ä¾‹"].mean()

    if recent_winner > early_winner + 0.05:
        trend["winner_rate_trend"] = "rising"
    elif recent_winner < early_winner - 0.05:
        trend["winner_rate_trend"] = "falling"

    trend["details"]["recent_winner_rate"] = round(float(recent_winner), 4)
    trend["details"]["early_winner_rate"] = round(float(early_winner), 4)

    # ========== é›†ä¸­åº¦å˜åŒ–é€Ÿç‡ï¼ˆåæ˜ ä¸»åŠ›æ“ä½œåŠ›åº¦ï¼‰ ==========
    if len(df) >= 10:
        conc_series = df["90é›†ä¸­åº¦"].iloc[-20:] if len(df) >= 20 else df["90é›†ä¸­åº¦"]
        conc_slope = _calc_slope(conc_series)
        trend["details"]["concentration_slope"] = round(float(conc_slope), 6)
        # æ–œç‡ä¸ºè´Ÿ = é›†ä¸­åº¦åœ¨ç¼©å° = ç­¹ç åœ¨é›†ä¸­
        if conc_slope < -0.001:
            trend["details"]["concentration_speed"] = "fast_concentrating"
        elif conc_slope < 0:
            trend["details"]["concentration_speed"] = "slow_concentrating"
        elif conc_slope > 0.001:
            trend["details"]["concentration_speed"] = "fast_dispersing"
        elif conc_slope > 0:
            trend["details"]["concentration_speed"] = "slow_dispersing"
        else:
            trend["details"]["concentration_speed"] = "stable"

    # ========== ä¸»åŠ›è¡Œä¸ºæ¨æ–­ï¼ˆæ ¸å¿ƒé€»è¾‘ï¼‰ ==========
    # äº¤å‰åˆ†æï¼šé›†ä¸­åº¦å˜åŒ– Ã— è·åˆ©æ¯”ä¾‹å˜åŒ– Ã— æˆæœ¬ä¸­å¿ƒå˜åŒ–
    accumulation_score = 0
    distribution_score = 0
    interpretations = []

    conc_trend = trend["concentration_trend"]
    cost_trend = trend["cost_center_trend"]
    winner_trend = trend["winner_rate_trend"]

    # ä¿¡å·1: ç­¹ç é›†ä¸­ + è·åˆ©æ¯”ä¾‹ä¸‹é™ â†’ å…¸å‹ä¸»åŠ›ä½ä½å¸ç­¹
    if conc_trend == "concentrating" and winner_trend == "falling":
        accumulation_score += 3
        interpretations.append("ğŸŸ¢ ç­¹ç é›†ä¸­+è·åˆ©æ¯”ä¾‹ä¸‹é™ï¼šå…¸å‹çš„ä¸»åŠ›ä½ä½å¸ç­¹ä¿¡å·")

    # ä¿¡å·2: ç­¹ç é›†ä¸­ + æˆæœ¬ä¸­å¿ƒä¸‹ç§» â†’ ä¸»åŠ›åœ¨ä½ä½æ”¶é›†ç­¹ç 
    if conc_trend == "concentrating" and cost_trend == "falling":
        accumulation_score += 2
        interpretations.append("ğŸŸ¢ ç­¹ç é›†ä¸­+æˆæœ¬ä¸‹ç§»ï¼šä¸»åŠ›åœ¨ä½ä½æ”¶é›†ç­¹ç ")

    # ä¿¡å·3: ç­¹ç é›†ä¸­ + è·åˆ©æ¯”ä¾‹ä¸Šå‡ â†’ ä¸»åŠ›æ‹‰å‡æ§ç›˜
    if conc_trend == "concentrating" and winner_trend == "rising":
        accumulation_score += 1
        interpretations.append("ğŸŸ¡ ç­¹ç é›†ä¸­+è·åˆ©æ¯”ä¾‹ä¸Šå‡ï¼šä¸»åŠ›æ‹‰å‡æ§ç›˜é˜¶æ®µ")

    # ä¿¡å·4: ç­¹ç åˆ†æ•£ + è·åˆ©æ¯”ä¾‹é«˜ â†’ ä¸»åŠ›é«˜ä½æ´¾å‘
    if conc_trend == "dispersing" and winner_trend == "rising":
        distribution_score += 3
        interpretations.append("ğŸ”´ ç­¹ç åˆ†æ•£+è·åˆ©æ¯”ä¾‹ä¸Šå‡ï¼šä¸»åŠ›é«˜ä½æ´¾å‘ä¿¡å·")

    # ä¿¡å·5: ç­¹ç åˆ†æ•£ + æˆæœ¬ä¸­å¿ƒä¸Šç§» â†’ é«˜ä½æ¢æ‰‹ï¼Œå¯èƒ½æ˜¯æ´¾å‘
    if conc_trend == "dispersing" and cost_trend == "rising":
        distribution_score += 2
        interpretations.append("ğŸ”´ ç­¹ç åˆ†æ•£+æˆæœ¬ä¸Šç§»ï¼šé«˜ä½æ¢æ‰‹æ´»è·ƒï¼Œè­¦æƒ•ä¸»åŠ›å‡ºè´§")

    # ä¿¡å·6: ç­¹ç åˆ†æ•£ + è·åˆ©æ¯”ä¾‹ä¸‹é™ â†’ ææ…Œæ€§æŠ›å”®æˆ–æ´—ç›˜
    if conc_trend == "dispersing" and winner_trend == "falling":
        distribution_score += 1
        accumulation_score += 1  # ä¹Ÿå¯èƒ½æ˜¯æ´—ç›˜
        interpretations.append("ğŸŸ¡ ç­¹ç åˆ†æ•£+è·åˆ©æ¯”ä¾‹ä¸‹é™ï¼šå¯èƒ½æ˜¯ææ…ŒæŠ›å”®æˆ–ä¸»åŠ›æ´—ç›˜")

    # ä¿¡å·7: æˆæœ¬ä¸­å¿ƒä¸‹ç§» + è·åˆ©æ¯”ä¾‹æä½ â†’ åº•éƒ¨åŒºåŸŸ
    latest_winner = float(df.iloc[-1]["è·åˆ©æ¯”ä¾‹"])
    if cost_trend == "falling" and latest_winner < 0.15:
        accumulation_score += 1
        interpretations.append("ğŸŸ¢ æˆæœ¬ä¸‹ç§»+è·åˆ©æ¯”ä¾‹æä½ï¼šå¯èƒ½å¤„äºåº•éƒ¨åŒºåŸŸ")

    # ä¿¡å·8: 70%é›†ä¸­åº¦æŒç»­æ”¶çª„ â†’ ä¸»åŠ›æ§ç›˜ç¨‹åº¦åŠ æ·±
    if len(df) >= 10:
        recent_70 = df["70é›†ä¸­åº¦"].iloc[-5:].mean()
        early_70 = df["70é›†ä¸­åº¦"].iloc[-15:-5].mean() if len(df) >= 15 else df["70é›†ä¸­åº¦"].iloc[:5].mean()
        if recent_70 < early_70 * 0.90:
            accumulation_score += 2
            interpretations.append("ğŸŸ¢ 70%ç­¹ç é›†ä¸­åº¦æ˜¾è‘—æ”¶çª„ï¼šä¸»åŠ›æ§ç›˜ç¨‹åº¦åŠ æ·±")
        elif recent_70 > early_70 * 1.10:
            distribution_score += 1
            interpretations.append("ğŸ”´ 70%ç­¹ç é›†ä¸­åº¦æ‰©å¤§ï¼šæŒä»“åˆ†æ­§åŠ å¤§")

    # ç»¼åˆåˆ¤æ–­ä¸»åŠ›æ€åº¦
    if accumulation_score >= 3 and accumulation_score > distribution_score * 2:
        trend["institutional_signal"] = "accumulating"
        trend["institutional_confidence"] = "high" if accumulation_score >= 5 else "medium"
    elif accumulation_score > distribution_score:
        trend["institutional_signal"] = "accumulating"
        trend["institutional_confidence"] = "low"
    elif distribution_score >= 3 and distribution_score > accumulation_score * 2:
        trend["institutional_signal"] = "distributing"
        trend["institutional_confidence"] = "high" if distribution_score >= 5 else "medium"
    elif distribution_score > accumulation_score:
        trend["institutional_signal"] = "distributing"
        trend["institutional_confidence"] = "low"
    else:
        trend["institutional_signal"] = "neutral"
        trend["institutional_confidence"] = "low"

    trend["details"]["accumulation_score"] = accumulation_score
    trend["details"]["distribution_score"] = distribution_score
    trend["interpretation"] = interpretations

    return trend


def _calc_slope(series: pd.Series) -> float:
    """è®¡ç®—åºåˆ—çš„çº¿æ€§å›å½’æ–œç‡"""
    try:
        y = series.values.astype(float)
        x = np.arange(len(y))
        if len(x) < 2:
            return 0.0
        slope = np.polyfit(x, y, 1)[0]
        return float(slope)
    except Exception:
        return 0.0


def _assess_chip_status(
    latest: Dict[str, Any],
    trend: Dict[str, Any],
    current_price: Optional[float] = None
) -> Dict[str, Any]:
    """
    ç»¼åˆè¯„ä¼°ç­¹ç çŠ¶æ€

    åŸºäºç­¹ç é›†ä¸­åº¦ã€è·åˆ©æ¯”ä¾‹ã€è¶‹åŠ¿ç­‰ç»¼åˆåˆ¤æ–­
    """
    assessment = {
        "chip_status": "neutral",       # concentrated / dispersed / neutral
        "pressure_level": "medium",     # low / medium / high
        "support_level": "medium",      # low / medium / high
        "signals": [],
        "summary": ""
    }

    winner_rate = latest["winner_rate"]
    concentration_90 = latest["concentration_90"]
    concentration_70 = latest["concentration_70"]
    avg_cost = latest["average_cost"]

    # --- ç­¹ç é›†ä¸­åº¦è¯„ä¼° ---
    # 90é›†ä¸­åº¦ < 10% è¡¨ç¤ºç­¹ç é«˜åº¦é›†ä¸­
    if concentration_90 < 0.10:
        assessment["chip_status"] = "highly_concentrated"
        assessment["signals"].append("ç­¹ç é«˜åº¦é›†ä¸­ï¼Œä¸»åŠ›æ§ç›˜æ˜æ˜¾")
    elif concentration_90 < 0.20:
        assessment["chip_status"] = "concentrated"
        assessment["signals"].append("ç­¹ç è¾ƒä¸ºé›†ä¸­")
    elif concentration_90 > 0.40:
        assessment["chip_status"] = "dispersed"
        assessment["signals"].append("ç­¹ç åˆ†æ•£ï¼ŒæŒä»“åˆ†æ­§è¾ƒå¤§")
    else:
        assessment["chip_status"] = "neutral"

    # --- è·åˆ©æ¯”ä¾‹è¯„ä¼° ---
    if winner_rate > 0.90:
        assessment["pressure_level"] = "high"
        assessment["signals"].append(f"è·åˆ©æ¯”ä¾‹æé«˜({winner_rate*100:.1f}%)ï¼Œå­˜åœ¨è¾ƒå¤§è·åˆ©å›åå‹åŠ›")
    elif winner_rate > 0.70:
        assessment["pressure_level"] = "medium_high"
        assessment["signals"].append(f"è·åˆ©æ¯”ä¾‹è¾ƒé«˜({winner_rate*100:.1f}%)ï¼Œæ³¨æ„è·åˆ©ç›˜å‹åŠ›")
    elif winner_rate < 0.10:
        assessment["pressure_level"] = "low"
        assessment["support_level"] = "low"
        assessment["signals"].append(f"è·åˆ©æ¯”ä¾‹æä½({winner_rate*100:.1f}%)ï¼Œå¤šæ•°ç­¹ç è¢«å¥—")
    elif winner_rate < 0.30:
        assessment["pressure_level"] = "low"
        assessment["signals"].append(f"è·åˆ©æ¯”ä¾‹è¾ƒä½({winner_rate*100:.1f}%)ï¼Œå¥—ç‰¢ç›˜è¾ƒå¤š")

    # --- å½“å‰ä»·æ ¼ä¸å¹³å‡æˆæœ¬çš„å…³ç³» ---
    if current_price and avg_cost > 0:
        price_vs_cost = (current_price - avg_cost) / avg_cost
        if price_vs_cost > 0.15:
            assessment["signals"].append(
                f"å½“å‰ä»·æ ¼é«˜äºå¹³å‡æˆæœ¬{price_vs_cost*100:.1f}%ï¼Œè·åˆ©ç›˜è¾ƒå¤š"
            )
        elif price_vs_cost < -0.15:
            assessment["signals"].append(
                f"å½“å‰ä»·æ ¼ä½äºå¹³å‡æˆæœ¬{abs(price_vs_cost)*100:.1f}%ï¼Œå¥—ç‰¢ç›˜å‹åŠ›å¤§"
            )
            assessment["support_level"] = "low"
        else:
            assessment["signals"].append("å½“å‰ä»·æ ¼æ¥è¿‘å¹³å‡æˆæœ¬ï¼Œå¤šç©ºåšå¼ˆåŒºé—´")

    # --- è¶‹åŠ¿ä¿¡å· ---
    conc_trend = trend.get("concentration_trend", "stable")
    cost_trend = trend.get("cost_center_trend", "stable")

    if conc_trend == "concentrating":
        assessment["signals"].append("ç­¹ç è¶‹äºé›†ä¸­ï¼Œå¯èƒ½æœ‰ä¸»åŠ›å¸ç­¹")
    elif conc_trend == "dispersing":
        assessment["signals"].append("ç­¹ç è¶‹äºåˆ†æ•£ï¼Œå¯èƒ½æœ‰ä¸»åŠ›æ´¾å‘")

    if cost_trend == "rising":
        assessment["signals"].append("æˆæœ¬ä¸­å¿ƒä¸Šç§»ï¼Œå¸‚åœºæ¢æ‰‹å……åˆ†")
    elif cost_trend == "falling":
        assessment["signals"].append("æˆæœ¬ä¸­å¿ƒä¸‹ç§»ï¼ŒæŒä»“æˆæœ¬é™ä½")

    # --- ä¸»åŠ›è¡Œä¸ºä¿¡å·ï¼ˆå¢å¼ºç‰ˆï¼‰ ---
    inst_signal = trend.get("institutional_signal", "neutral")
    inst_confidence = trend.get("institutional_confidence", "low")
    interpretations = trend.get("interpretation", [])

    inst_signal_map = {
        "accumulating": "ä¸»åŠ›å¸ç­¹",
        "distributing": "ä¸»åŠ›æ´¾å‘",
        "neutral": "ä¸»åŠ›æ€åº¦ä¸æ˜",
    }
    inst_confidence_map = {
        "high": "å¼º",
        "medium": "ä¸­ç­‰",
        "low": "å¼±",
    }

    assessment["institutional_signal"] = inst_signal
    assessment["institutional_confidence"] = inst_confidence
    assessment["institutional_interpretation"] = interpretations

    if inst_signal != "neutral":
        assessment["signals"].append(
            f"ä¸»åŠ›è¡Œä¸ºç ”åˆ¤ï¼š{inst_signal_map.get(inst_signal, 'ä¸æ˜')}ï¼ˆä¿¡å·å¼ºåº¦ï¼š{inst_confidence_map.get(inst_confidence, 'å¼±')}ï¼‰"
        )

    # å¤šå‘¨æœŸä¿¡æ¯
    multi_period = trend.get("multi_period", {})
    if multi_period:
        assessment["multi_period_summary"] = multi_period

    # --- ç”Ÿæˆæ€»ç»“ ---
    summary_parts = []

    # é›†ä¸­åº¦æè¿°
    status_map = {
        "highly_concentrated": "ç­¹ç é«˜åº¦é›†ä¸­",
        "concentrated": "ç­¹ç è¾ƒé›†ä¸­",
        "dispersed": "ç­¹ç åˆ†æ•£",
        "neutral": "ç­¹ç åˆ†å¸ƒé€‚ä¸­"
    }
    summary_parts.append(status_map.get(assessment["chip_status"], "ç­¹ç åˆ†å¸ƒé€‚ä¸­"))

    # è·åˆ©æ¯”ä¾‹æè¿°
    summary_parts.append(f"è·åˆ©æ¯”ä¾‹{winner_rate*100:.1f}%")

    # å¹³å‡æˆæœ¬
    summary_parts.append(f"å¹³å‡æˆæœ¬{avg_cost:.2f}å…ƒ")

    # è¶‹åŠ¿æè¿°
    trend_desc_map = {
        "concentrating": "ç­¹ç è¶‹äºé›†ä¸­",
        "dispersing": "ç­¹ç è¶‹äºåˆ†æ•£",
        "stable": "ç­¹ç åˆ†å¸ƒç¨³å®š"
    }
    summary_parts.append(trend_desc_map.get(conc_trend, ""))

    # ä¸»åŠ›è¡Œä¸ºæè¿°
    if inst_signal == "accumulating":
        summary_parts.append(f"ç ”åˆ¤ä¸»åŠ›å¸ç­¹ï¼ˆ{inst_confidence_map.get(inst_confidence, 'å¼±')}ä¿¡å·ï¼‰")
    elif inst_signal == "distributing":
        summary_parts.append(f"ç ”åˆ¤ä¸»åŠ›æ´¾å‘ï¼ˆ{inst_confidence_map.get(inst_confidence, 'å¼±')}ä¿¡å·ï¼‰")

    assessment["summary"] = "ï¼Œ".join(filter(None, summary_parts)) + "ã€‚"

    return assessment


def _empty_chip_result(error_msg: str) -> Dict[str, Any]:
    """è¿”å›ç©ºçš„ç­¹ç åˆ†æç»“æœï¼ˆæ•°æ®è·å–å¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
    return {
        "latest": {},
        "trend": {},
        "assessment": {
            "chip_status": "unknown",
            "pressure_level": "unknown",
            "support_level": "unknown",
            "signals": [],
            "summary": f"ç­¹ç æ•°æ®è·å–å¤±è´¥: {error_msg}"
        },
        "error": error_msg
    }


class ChipAnalyzer:
    """
    ç­¹ç åˆ†å¸ƒåˆ†æå™¨ç±»

    æä¾›ç­¹ç åˆ†æçš„é¢å‘å¯¹è±¡æ¥å£
    """

    def __init__(self):
        self.logger = get_logger(self.__class__.__name__)

    def analyze(
        self,
        symbol: str,
        current_price: Optional[float] = None,
        adjust: Literal["qfq", "hfq", ""] = "qfq"
    ) -> Dict[str, Any]:
        """æ‰§è¡Œç­¹ç åˆ†æ"""
        return analyze_chip_distribution(symbol, current_price, adjust)

    def get_raw_data(
        self,
        symbol: str,
        adjust: Literal["qfq", "hfq", ""] = "qfq"
    ) -> pd.DataFrame:
        """è·å–åŸå§‹ç­¹ç åˆ†å¸ƒæ•°æ®"""
        return fetch_chip_distribution(symbol, adjust)
